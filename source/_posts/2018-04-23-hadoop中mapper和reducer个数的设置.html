---
title: "Hadoop中的Mapper和Reducer数量设定"
date: 2018-04-24
layout: post
categories: 
- 大数据
tags: 
- 大数据 
- Hadoop
published: true
comments: 
---
<p>
对于大数据处理，特别是T级别以上的海量数据，
由于数据量大大超过了单机运算能力，需要通过分布式的方法来对数据进行处理。
Hadoop作为大数据领域的明星项目，提供了MapReduce分布式编程框架,
其基于分而治冶的思想，将海量数据拆分为大量的小数据块，从而在多个节点并行处理海量数据。
</p>

<p>
虽然MapReduce通过分布式计算、map端"数据本地化优化“等不同层次的策略来提升数据处理任务的执行效率，
但由于实际处理的数据量较大，一个典型的MapReduce作业往往需要花费数分钟到数小时来完成。
并且在任务执行的过程中，MapReduce作业还将占用大量的网络带宽和计算资源，从而降低了整个集群的计算能力。
为了进一步提升MapReduce的执行效率，需要对MapReduce任务进行调优。
而最为直接有效的一种调优方式就是调整Mapper和Reducer的数量。
</p>

<div id="outline-container-org822556c" class="outline-2">
<h2 id="org822556c">Mapper的数量设定</h2>
<div class="outline-text-2" id="text-org822556c">
<p>
在对Mapper调优的过程中，一个经验法则是：
map任务最好拥有一分钟以上的运行时间。
因为如果任务运行时间过短，将导致在整个作业的执行过程中任务启动所花费的时间过大，从而降低了实际的任务执行效率。
对map任务的运行时间影响最大的是Mapper的个数，不过与Reducer不同，Mapper的个数是无法显示指定的。
调节Mapper数量的一种方式是设置参数mapred.jobtracker.maxtasks.per.job，
但其只能限制每个job中并发运行的map或reduce任务的上限，而当实际运行的map数低于该上限时，该参数将失效。
如果想要对Mapper个数进行更加直接有效的控制，需要指定输入数据的分片大小。
</p>

<p>
输入分片(input split)是MapReduce框架为使map任务能并行处理海量数据记录，
为每个map任务单独划分的一个等长小数据块。
在MapReduce框架中，输入数据分片通过InputFormat接口完成。
为方便程序员使用，Hadoop为最常见的文件数据源提供了大量基于FileInputFormat基类的实现类。
因此只要掌握了FileInputFormat的数据分片原理，也就知道了各种常见的数据源实现类是如何进行数据分片的了。
</p>

<p>
FileInputFormat提供了三个属性参数来控制实际的分片大小：mapreduce.input.fileinputformat.split.minsize, mapreduce.input.fileinputformat.split.maxsize以及dfs.blocksize。
这三个参数分别表示一个文件分片最小的有效字节数、最大字节数以及HDFS中块的大小。
利用公式splitSize = max(minimumSize, min(maximumSize, blockSize))，可以通过改变上述三个参数来调节最终的分片大小。
在调节分片大小时需要防止分片切分过小，避免管理分片和构建map任务的时间在整个任务运行周期中占比过大。
但分片划分也不是越大越好，至少不应大于块大小，因为那时将无法确保存储有该切片的多个数据块位于单个节点中，从而增加了执行map任务时的网络传输。
因此对于大多数作业来说，一个合理的分片大小趋向于HDFS的一个块的大小，默认是128MB。
</p>

<p>
需要注意的是，虽然输入分片划分是本着尽量拆分成等长数据块的原则，但最后的分片大小并不完全一致。
因为数据分片对有效字节数小于maximumSize的文件并不进行拆分，而且进行拆分的大文件的大小往往不会为文件块大小的整数倍。
分片大小与指向分片数据的引用一起包含在输入分片中，供application master调度使用。
在调度的过程中，Hadoop通过优先处理最大的分片以最小化实际运行时间。
</p>
</div>
</div>

<div id="outline-container-org1dd2598" class="outline-2">
<h2 id="org1dd2598">Reducer的数量设定</h2>
<div class="outline-text-2" id="text-org1dd2598">
<p>
Reducer的个数是由用户独立设置的，在默认情况下只有一个Reducer。
它的个数既可以使用命令行参数设置（mapreduce.job.reduces=number），也可以在程序中制定（job.setNumReduceTasks(number)）。
</p>

<p>
为了更加高效地完成reduce任务，Reducer的个数需要依据自己的任务特点和机器负载情况进行选择。
Hadoop权威指南给出的一条经验法则是：目标Reducer保持在每个运行5分钟左右，且产生至少一个HDFS块的输出。
而Apache的MapReduce官方教程中给出的建议是：Reducer个数应该设置为0.95或者1.75乘以节点数与每个节点的容器数的乘积。
当乘数为0.95时，map任务结束后所有的reduce将会立刻启动并开始转移数据，
此时队列中无等待任务，该设置适合reudce任务执行时间短或者reduce任务在个节点的执行时间相差不大的情况；
当乘数为1.75时，运行较快的节点将在完成第一轮reduce任务后，可以立即从队列中取出新的reduce任务执行，
由于该reduce个数设置方法减轻了单个reduce任务的负载，并且运行较快的节点将执行新的reduce任务而非空等执行较慢的节点，其拥有更好的负载均衡特性。
</p>
</div>
</div>

<div id="outline-container-orgb4af80d" class="outline-2">
<h2 id="orgb4af80d">参考</h2>
<div class="outline-text-2" id="text-orgb4af80d">
<p>
<a href="https://book.douban.com/subject/27115351/">Hadoop权威指南</a>
</p>

<p>
<a href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Reducer">MapReduce Tutorial</a>
</p>

<p>
<a href="https://stackoverflow.com/questions/21980110/what-is-ideal-number-of-reducers-on-hadoop">What is Ideal number of reducers on Hadoop?</a>
</p>

<p>
<a href="https://stackoverflow.com/questions/20818370/how-to-set-the-number-of-mappers-in-new-hadoop-api">How to set the number of mappers in new Hadoop api?</a>
</p>
</div>
</div>
